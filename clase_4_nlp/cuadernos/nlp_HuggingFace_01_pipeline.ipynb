{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:red\"><center>Transformers- Procesamiento de Lenguaje Natural </center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>HuggingFace pipeline</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Autores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Diseño gráfico y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Maria del Pilar Montenegro Reyes, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Asistentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Referencias</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [HuggingFace. Transformers ](https://huggingface.co/transformers/)\n",
    "1. [HuggingFace. Intro pipeline](https://huggingface.co/course/chapter1/3?fw=pt)\n",
    "1. [Tutorial Transformer de Google](https://www.tensorflow.org/text/tutorials/transformer)\n",
    "1. [Transformer-chatbot-tutorial-with-tensorflow-2](https://blog.tensorflow.org/2019/05/transformer-chatbot-tutorial-with-tensorflow-2.html) \n",
    "1. [Transformer Architecture: The positional encoding](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)\n",
    "1. [Illustrated Auto-attención](https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a)\n",
    "1. [Illustrated Attention](https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3#0458)\n",
    "1. [Neural Machine Translation by Jointly Learning to Align and Translate (Bahdanau et. al, 2015)](https://arxiv.org/pdf/1409.0473.pdf)\n",
    "1. [Effective Approaches to Attention-based Neural Machine Translation (Luong et. al, 2015)](https://arxiv.org/pdf/1508.04025.pdf)\n",
    "1. [Attention Is All You Need (Vaswani et. al, 2017)](https://arxiv.org/pdf/1706.03762.pdf)\n",
    "1. [Self-Attention GAN (Zhang et. al, 2018)](https://arxiv.org/pdf/1805.08318.pdf)\n",
    "1. [Sequence to Sequence Learning with Neural Networks (Sutskever et. al, 2014)](https://arxiv.org/pdf/1409.3215.pdf)\n",
    "1. [TensorFlow’s seq2seq Tutorial with Attention (Tutorial on seq2seq+attention)](https://github.com/tensorflow/nmt)\n",
    "1. [Lilian Weng’s Blog on Attention (Great start to attention)](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html#a-family-of-attention-mechanisms)\n",
    "1. [Jay Alammar’s Blog on Seq2Seq with Attention (Great illustrations and worked example on seq2seq+attention)](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)\n",
    "1. [Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation (Wu et. al, 2016)](https://arxiv.org/pdf/1609.08144.pdf)\n",
    "1. [Adam: A method for stochastic optimization](https://arxiv.org/pdf/1412.6980.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Contenido</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Introducción](#Introducción)\n",
    "* [Pipeline de HuggingFace](#Pipeline-de-HuggingFace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las tareas del procesamiento del lenguaje natural moderno se dividen escencialmente en:\n",
    "\n",
    "1. Clasificación de textos. Por ejemplo, análisis de sentimiento.\n",
    "1. Generación automática de textos, basados en una frase inicial.\n",
    "1. Generación de texto en contexto, llenando espacios vacios enmascarados con máscaras `masked text`.\n",
    "1. Clasificación de cada una de las palabras en una frase:  Por ejemplo: sustantivo, verbo adjetivo, o por ejemplo `ner`: named entity recognition. ciudad, nombre de persona, localización, organización. Este proceso se denomina inferencia textual.\n",
    "1. Generación de una respuesta a partir de una pregunta.\n",
    "1. Traducción de un lenguaje a otro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Pipeline de HuggingFace</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta lección se introduce `pipeline`, que es una función de HuggingFace que permite hacer uso directamente de modelos pre-entrenados quer (básicanete en inglés). Esto implica no es necesario pre-procesamiento no post-procesamiento para obtener resultados directamente usando los modelos pre-entrenados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para correr el cuaderno original  de HuggingFace en Colab vaya a  [HuggingFace notebook](https://huggingface.co/course/chapter1/3?fw=tf). Versión Torch [aquí](https://huggingface.co/course/chapter1/3?fw=pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Inicialmente instalemos los siguientes productos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!conda install -c huggingface transformers\n",
    "#!conda install -c conda-forge sentencepiece\n",
    "#!conda install -c conda-forge ipywidgets\n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "#!conda install -c huggingface -c conda-forge datasets\n",
    "#!conda install -c conda-forge pysoundfile\n",
    "#!conda install -c pytorch torchaudio\n",
    "#!conda install -c pytorch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier = pipeline(\"sentiment-analysis\",model=('distilbert-base-uncased-finetuned-sst-2-english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9950999617576599}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I've been waiting for a HuggingFace course my hole life\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\", \n",
    "    \"I hate this so much!\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimiento = pipeline(\"sentiment-analysis\",model=\"finiteautomata/beto-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEG', 'score': 0.9991681575775146},\n",
       " {'label': 'POS', 'score': 0.9985315799713135}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimiento(['odio esta cochina vida ','Estamos contentos de terminar el diplomado!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de texto a partir de una frase inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' I was expecting for you for the weekend. You\\'re only one person of your kind here, you really are amazing. I have to show you that I love you for who you are, that I love you for what you are.\\n\\n\\n\"'}]\n"
     ]
    }
   ],
   "source": [
    "text= generator(' I was expecting for you',max_length=50)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generador = pipeline(\"text-generation\", model=\"DeepESP/gpt2-spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'generated_text': ' es una expléndida tarde y con una sonrisa en la cara, pero no se ha reído. \\n\\n—¿Cómo? No me digas que vas a dejar de chivarte. \\n\\n—Pues sí, que me cago en una puta'}], [{'generated_text': 'mañana tengo mucho trabajo y estoy deseando volver a acostarme. \\n\\n—No deberías hacer esto antes. Siempre te he escuchado decir que no te va a durar mucho en el día. \\n\\n—Ya te lo dije ayer. Eres la primera persona'}]]\n"
     ]
    }
   ],
   "source": [
    "texto= generador([' es una expléndida tarde', 'mañana tengo mucho trabajo'],max_length=50)\n",
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '¿Cómo te atreves a pensar eso de mi padre cuando todo sucede? ¿Cómo es tu madre? ¿Qué es para él? ¿Cómo puedo confiar en ti cuando puedes confiar en mí cuando tu madre y tú ya no sois nada? \\n\\nEl'}, {'generated_text': '¿Cómo te atreves a pensar eso de mi manera natural? … En resumen, eres tú la que tiene que decir: \"Si yo pudiera hablar sola no tenía la más mínima duda de que hablarías contigo\". \\n\\nLa respuesta de Pascal pareció sorprender'}]\n",
      "\n",
      "[{'generated_text': '¿Cómo te atreves a pensar eso de mi padre cuando todo sucede? ¿Cómo es tu madre? ¿Qué es para él? ¿Cómo puedo confiar en ti cuando puedes confiar en mí cuando tu madre y tú ya no sois nada? \\n\\nEl'}, {'generated_text': '¿Cómo te atreves a pensar eso de mi manera natural? … En resumen, eres tú la que tiene que decir: \"Si yo pudiera hablar sola no tenía la más mínima duda de que hablarías contigo\". \\n\\nLa respuesta de Pascal pareció sorprender'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textos = generador('¿Cómo te atreves a pensar eso de mi',\n",
    "          max_length=50,\n",
    "          num_return_sequences=2,\n",
    "         )\n",
    "\n",
    "for i in textos:\n",
    "    print(textos)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de texto en contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline('fill-mask', model = 'roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'This course teach you about business models.',\n",
       "  'score': 0.3803407847881317,\n",
       "  'token': 265,\n",
       "  'token_str': ' business'},\n",
       " {'sequence': 'This course teach you about financial models.',\n",
       "  'score': 0.05075811594724655,\n",
       "  'token': 613,\n",
       "  'token_str': ' financial'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker('This course teach you about <mask> models.', top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import BertTokenizer as tokenizer\n",
    "MASK_TOKEN = tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#llenar_mascara = pipeline('fill-mask', model = 'dccuchile/bert-base-spanish-wwm-cased')\n",
    "llenar_mascara = pipeline('fill-mask', model = 'bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "llenar_mascara('estamos terminado este diplomado {} en una semana.'.format(MASK_TOKEN), top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llenar_mascara('estamos terminado este diplomado <MASK> en una semana.', top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconocimiento de entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4256f14aef41b487971f09091fae23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2195c756ecd48e58972f44df3b24607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/413M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcc8ea9307e412cb064158fcf989ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2752296bc1e745f5850fb5bb167af6c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9994b4853d0a4aa7a4bd37e5413aedcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2c78ea81c840c69545ee95f48e418d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alvaro/anaconda3/envs/huggingface/lib/python3.8/site-packages/transformers/pipelines/token_classification.py:128: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline('ner', model='dslim/bert-base-NER', grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.99042225,\n",
       "  'word': 'Alice',\n",
       "  'start': 11,\n",
       "  'end': 16},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9747827,\n",
       "  'word': 'HuggingFace',\n",
       "  'start': 31,\n",
       "  'end': 42},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99645185,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 46,\n",
       "  'end': 54}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"My name is Alice and I work at HuggingFace in Brooklyn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edbcb2b7b90482f93f4ab1aecfb223c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/829 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251e4eceabd74290a2493b29f42c4a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/419M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898a410ef85c4874a42ab8665ed85552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/136 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d095e860e1f41f9965eea822ebe27d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/237k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5ea120df154a0b83c378644fe29ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_espa = pipeline('ner', model='mrm8488/bert-spanish-cased-finetuned-ner', grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9984431,\n",
       "  'word': 'Alvar',\n",
       "  'start': 13,\n",
       "  'end': 18},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.67436606,\n",
       "  'word': '##o',\n",
       "  'start': 18,\n",
       "  'end': 19},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99977064,\n",
       "  'word': 'Bogotá',\n",
       "  'start': 29,\n",
       "  'end': 35},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9995036,\n",
       "  'word': 'Universidad Nacional',\n",
       "  'start': 52,\n",
       "  'end': 72}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_espa('Mi nombre en Alvaro, vivo en Bogotá y trabajo en la Universidad Nacional')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuesta a preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answer = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6481999754905701, 'start': 30, 'end': 41, 'answer': 'HuggingFace'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answer(\n",
    "    question=\"Where do I work?\",\n",
    "    context=\"My name is John and I work at HuggingFace in Brooklyn\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregunta_respuesta = pipeline(\"question-answering\", model=\"mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.42126110196113586, 'start': 27, 'end': 33, 'answer': 'Bogotá'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pregunta_respuesta(\n",
    "    question='¿De donde soy?',\n",
    "    context= 'Nací en Cali, pero vivo en Bogotá'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.9135797619819641, 'start': 27, 'end': 33, 'answer': 'Bogotá'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pregunta_respuesta(\n",
    "    question='¿En donde resido?',\n",
    "    context= 'Nací en Cali, pero vivo en Bogotá'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model='facebook/bart-large-cnn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'America has changed dramatically during recent years. The number of graduates in traditional engineering disciplines has declined. There are declining offerings in engineering subjects dealing with infrastructure, the environment, and related issues. Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering.'}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer_spa = pipeline(\"summarization\", model='mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Los Estados Unidos han cambiado drásticamente en los últimos años. La mayoría de los programas de ingeniería de las principales universidades estadounidenses se concentra en el estudio de las ciencias de la ingenieria. China como la India, respectivamente, se gradúan seis y ocho veces m more ingenieros tradicionales.'}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = str(\"\"\"\n",
    "        Los Estados Unidos han cambiado drásticamente en los últimos años. \n",
    "        No sólo ha disminuido el número de graduados en disciplinas tradicionales \n",
    "        de ingeniería, como la ingeniería mecánica, civil, eléctrica, química y \n",
    "        aeronáutica, sino que en la mayoría de los programas de ingeniería de \n",
    "        las principales universidades estadounidenses se concentra y fomenta en \n",
    "        gran medida el estudio de las ciencias de la ingeniería. \n",
    "        Como resultado, hay una disminución de la oferta en temas de ingeniería\n",
    "        relacionados con la infraestructura, el medio ambiente y cuestiones conexas, \n",
    "        y una mayor concentración en temas de alta tecnología, apoyando en gran medida \n",
    "        desarrollos científicos cada vez más complejos. Si bien este último es importante, \n",
    "        no debe ser a expensas de la ingeniería más tradicional. Las economías en rápido \n",
    "        desarrollo, como China y la India, así como otros países industriales de \n",
    "        Europa y Asia, siguen fomentando y promoviendo la enseñanza de la ingeniería. \n",
    "        Tanto China como la India, respectivamente, se gradúan seis y ocho veces más \n",
    "        ingenieros tradicionales que los Estados Unidos. Otros países industriales \n",
    "        mantienen como mínimo su producción, mientras que los Estados Unidos sufren\n",
    "        una disminución cada vez más grave del número de graduados en ingeniería y \n",
    "        una falta de ingenieros bien educados.\n",
    "\"\"\")\n",
    "summarizer(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer_multi = pipeline(\"summarization\", model=\"csebuetnlp/mT5_multilingual_XLSum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Los Estados Unidos están cambiando drásticamente en los últimos años.'}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer_multi(texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traducción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Los Estados Unidos han cambiado drásticamente en los últimos años. No sólo ha disminuido el número de graduados en disciplinas tradicionales de ingeniería, como la ingeniería mecánica, civil, eléctrica, química y aeronáutica, sino que en la mayoría de los programas de ingeniería de las principales universidades estadounidenses se concentra y fomenta en gran medida el estudio de las ciencias de la ingeniería. Como resultado, hay una disminución de la oferta en temas de ingeniería relacionados con la infraestructura, el medio ambiente y cuestiones conexas, y una mayor concentración en temas de alta tecnología, apoyando en gran medida desarrollos científicos cada vez más complejos. Si bien este último es importante, no debe ser a expensas de la ingeniería más tradicional. Las economías en rápido desarrollo, como China y la India, así como otros países industriales de Europa y Asia, siguen fomentando y promoviendo la enseñanza de la ingeniería. Tanto China como la India, respectivamente, se gradúan seis y ocho veces más ingenieros tradicionales que los Estados Unidos. Otros países industriales mantienen como mínimo su producción, mientras que los Estados Unidos sufren una disminución cada vez más grave del número de graduados en ingeniería y una falta de ingenieros bien educados.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "translator(\"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'América ha cambiado dramáticamente durante los últimos años. El número de graduados de ingeniería en los EE.UU. ha disminuido en las disciplinas tradicionales de ingeniería, como la ingeniería mecánica, civil, eléctrica, química y aeronáutica. Economías en rápido desarrollo como China e India siguen alentando y promoviendo la enseñanza de la ingeniería.'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "translator(\"\"\"America has changed dramatically during recent years . \n",
    "           The number of engineering graduates in the U.S. \n",
    "           has declined in traditional engineering disciplines such as mechanical, civil,    \n",
    "           electrical, chemical, and aeronautical engineering . \n",
    "           Rapidly developing economies such as China and India continue to \n",
    "           encourage and advance the teaching of engineering .\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación de cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Clasificación de textos que no han sido clasificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d8e4ca48674219a330e5eab2d95c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af16e904320f414a83c38992f58d65de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c58bdc2cb8774887a22bae90aa910074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef563fd86f484cb48d68c994d0bd9d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e488b8f360254ce3934ece9214860d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5429cc2a13647ce8e027e3f8f442358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformer library',\n",
       " 'labels': ['education', 'bussines', 'politics'],\n",
       " 'scores': [0.9465058445930481, 0.04198963940143585, 0.011504470370709896]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('zero-shot-classification', model='')\n",
    "classifier(\n",
    "          \"This is a course about the Transformer library\",\n",
    "          candidate_labels=['education', 'politics', 'bussines']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso de cualquier modelo del hub en una tubería (pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada tarea específica se puede especificar un modelo en particular. En este ejemplo vamos a seleccionar el modelo *distilgpt2* para generar texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041d2034ce134abeb319793129aa33f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c332f9c93a6c42e1959b3bd1b73e2877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcda52e2cf7d4ccf8fb8ccd181f5b01a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79c5daeba3f4dee904cb4032680ea7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d481f17d3cc14798b299d3252acd1e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to successfully read and write online and how to write real time content for educational purposes.'},\n",
       " {'generated_text': 'In this course, we will teach you how to build and use the open source compiler to build a fully functional, flexible, highly open and easy to'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model='distilgpt2')\n",
    "generator(\n",
    "    'In this course, we will teach you how to',\n",
    "    max_length=30,\n",
    "num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos en Español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Su casa es un asco.- ¡Y que lo digas!¡Con las sábanas de la abuela en la lavadora!Y ahora tengo que limpiarla'},\n",
       " {'generated_text': 'Su casa es un asco.Y además, se ve así.Con un sombrero de copa y todos esos libros...Y en la cocina me llaman de'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model='mrm8488/spanish-gpt2')\n",
    "generator(\n",
    "    'Su casa es un asco',\n",
    "    max_length=30,\n",
    "num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traductores Español-Inglés, Inglés-Español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3556d742774fd28c3217460e88425c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/826k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60106380840d4e5da6287dfadcd05b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030a91c6f6c04459850c6552b19a302d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'I hate this very much.'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator_sp_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
    "translator_sp_en(\"Odio mucho esto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'Odio mucho esto.'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "translator(\"I hate this very much\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinando modelos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "translator_es_en = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
    "translator_en_es = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9995800852775574}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase_espanol = 'odio mucho esto'\n",
    "frase_ingles = translator_es_en(frase_espanol)[0]['translation_text']\n",
    "\n",
    "classifier(frase_ingles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frase_espanol = 'eso está muy bien'\n",
    "frase_ingles = translator_es_en(frase_espanol)[0]['translation_text']\n",
    "\n",
    "classifier(frase_ingles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### speech2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import sentencepiece\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"airesearch/wav2vec2-large-xlsr-53-thh\")\n",
    "processor = Speech2TextProcessor.from_pretrained(\"airesearch/wav2vec2-large-xlsr-53-thh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_array(batch):\n",
    "     speech, _ = sf.read(batch[\"file\"])\n",
    "     batch[\"speech\"] = speech\n",
    "     return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "inputs = processor(ds[\"speech\"][0], sampling_rate=16_000, return_tensors=\"pt\")\n",
    "generated_ids = model.generate(input_ids=inputs[\"input_features\"], attention_mask=inputs[\"attention_mask], forced_bos_token_id=processor.tokenizer.lang_code_to_id[\"fr\"])\n",
    "\n",
    "translation = processor.batch_decode(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    Wav2Vec2ForCTC,\n",
    "    Wav2Vec2Processor,\n",
    ")\n",
    "import torch\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93df7107fae54fe3bae90288904dc4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/158 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda9ff8422f048f6968c96cff1294531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/370 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e853e3297ee1499baeace60731add409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/380 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c7b46725e64e52ba48505d80f9eebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"facebook/wav2vec2-large-xlsr-53-spanish\"\n",
    "#device = \"cuda\"\n",
    "device = \"cpu\"\n",
    "\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'  # noqa: W605\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name).to(device)\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"common_voice\", \"es\", split=\"test\", data_dir=\"./cv-corpus-6.1-2020-12-11\")\n",
    "\n",
    "resampler = torchaudio.transforms.Resample(orig_freq=48_000, new_freq=16_000)\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = torchaudio.load(batch[\"path\"])\n",
    "    batch[\"speech\"] = resampler.forward(speech.squeeze(0)).numpy()\n",
    "    batch[\"sampling_rate\"] = resampler.new_freq\n",
    "    batch[\"sentence\"] = re.sub(chars_to_ignore_regex, '', batch[\"sentence\"]).lower().replace(\"’\", \"'\")\n",
    "    return batch\n",
    "    \n",
    "ds = ds.map(map_to_array)\n",
    "\n",
    "def map_to_pred(batch):\n",
    "    features = processor(batch[\"speech\"], sampling_rate=batch[\"sampling_rate\"][0], padding=True, return_tensors=\"pt\")\n",
    "    input_values = features.input_values.to(device)\n",
    "    attention_mask = features.attention_mask.to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values, attention_mask=attention_mask).logits\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"predicted\"] = processor.batch_decode(pred_ids)\n",
    "    batch[\"target\"] = batch[\"sentence\"]\n",
    "    return batch\n",
    "    \n",
    "result = ds.map(map_to_pred, batched=True, batch_size=16, remove_columns=list(ds.features.keys()))\n",
    "\n",
    "wer = load_metric(\"wer\")\n",
    "\n",
    "print(wer.compute(predictions=result[\"predicted\"], references=result[\"target\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
