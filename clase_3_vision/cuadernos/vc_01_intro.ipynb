{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810405a1-2210-417e-ae59-ab242d1ec6c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<img src=\"../imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f7fc31-df30-4653-a932-c8a2a49da5f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <span style=\"color:red\"><center>Minicurso  de Inteligencia Artificial<center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70bf7b2-6518-4760-93f1-413603d8363a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:Green\"><center>Introducción a la visión artificial<center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e64778e-9280-492f-9e8c-ab1899745a0f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2517bd57-bb6a-46b0-952f-0ebd7d8fea88",
   "metadata": {},
   "source": [
    "1. Alvaro  Montenegro, PhD, ammontenegrod@unal.edu.co\n",
    "1. Camilo José Torres Jiménez, Msc, cjtorresj@unal.edu.co\n",
    "1. Daniel  Montenegro, Msc, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043d1c3-2f71-4f8f-8e0d-439f8ffba428",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Asesora Medios y Marketing digital</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354f327-b4c3-47f1-ac95-8926b918bac1",
   "metadata": {},
   "source": [
    "4. Maria del Pilar Montenegro, pmontenegro88@gmail.com\n",
    "5. Jessica López Mejía, jelopezme@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5342542f-108f-4bf8-80c2-3e974b24be91",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Jefe Jurídica</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af589b9b-d48f-45b3-bc79-bd21ba835994",
   "metadata": {},
   "source": [
    "6. Paula Andrea Guzmán, guzmancruz.paula@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09135b4-8bc7-430f-98ca-a61ed91e55de",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Coordinador Jurídico</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c1749-16d2-40e9-9b3a-b0d352c0b964",
   "metadata": {},
   "source": [
    "7. David Fuentes, fuentesd065@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b42a2b-7711-4d6d-8e4e-471694757b0d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Desarrolladores Principales</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5e4921-6da5-455c-a50d-fd010b27ab41",
   "metadata": {},
   "source": [
    "8. Dairo Moreno, damoralesj@unal.edu.co\n",
    "9. Joan Castro, jelopezme@unal.edu.co\n",
    "10. Bryan Riveros, briveros@unal.edu.co\n",
    "11. Rosmer Vargas, rovargasc@unal.edu.co\n",
    "12. Venus Puertas, vpuertasg@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a78ad31-0e21-42e3-8bf2-4587e30562d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Expertos en Bases de Datos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccf5d4f-9354-4fcf-bbe3-adb22206e50d",
   "metadata": {},
   "source": [
    "13. Giovvani Barrera, udgiovanni@gmail.com\n",
    "14. Camilo Chitivo, cchitivo@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bbcf4c-0268-4b0d-8c61-a5a9a56c1b95",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Introducción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e5caf-e2a1-4874-a53c-149e6054283c",
   "metadata": {},
   "source": [
    "Los seres vivos, particularmente los humanos, tenemos capacidades increibles que, en muchos casos, damos por sentado. Una de estas es la vista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc207ec-d071-429d-b216-98b4bf609245",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../imagenes/city.jpg\" width=\"400\" height=\"400\" align=\"left\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Viendo una sola imagen somos capaces de suponer/inferir muchas cosas. ¿Qué ejemplos pueden pensar?\n",
    "\n",
    "Para los humanos, esta tarea de describir, comparar, diferenciar es muy sencilla. Los computadores pueden hacer eso sin algo, o mucha, ayuda.\n",
    "\n",
    "Supongamos que conectamos una cámara al computador y queremos obtener toda la información que podamos sobre lo que se capture. Necesitamos métodos que permitan que pueda diferenciar bordes, colores, identificar objetos, entre otro montón de cosas. Eso es lo que busca la visión artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05529ae-1f39-4450-b18b-d2018b32382b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../imagenes/CNN_arquitecture.png\" width=\"600\" height=\"400\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "El mayor de los avances en el campo de la visión por computadora es el uso de bases de datos y Redes Convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc7ad31-dda5-4109-882b-361a568d7193",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Aplicaciones</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1136a92b-7a80-40d1-908d-72493b63d314",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Rastreo de contornos\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../imagenes/contour_detection.gif\" width=\"300\" height=\"300\"/>\n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b7c4fd-3b93-4374-bcd8-486a2fae9770",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Reconocimiento Facial\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../imagenes/facial_detection.gif\" width=\"400\" height=\"400\"/>\n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6312d61-768d-4f0a-82fd-841b2f375331",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Detección de objetos\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../imagenes/object_detection.gif\" width=\"400\" height=\"400\"/>\n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3e1170-ecdf-4941-ac62-86aaf31f7930",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Estimación de poses\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../imagenes/body_pose.gif\" width=\"200\" height=\"400\"/>\n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e2dbc-b5d2-4ce1-867f-8066954bef39",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Convolución: El mayor aliado</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c6985-5d89-403c-ba4c-b5afc0355179",
   "metadata": {},
   "source": [
    "Las imagenes pueden representarse por números a través de ciertas codificaciones. Si una imágen está en escala de grises, cada pixel puede aplicarse como un número de 0 a 255\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../imagenes/imagematrix.png\" width=\"600\" height=\"400\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Esta puede ser una forma adecuada para que el computador comprenda el concepto de imágen, pero esto se vuelve cada vez más complicado si las imagenes son más grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f59cb-9425-480e-b362-ac7fc1367784",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Y esto solo empeora cuando se tratan de imágenes a color, que tienen muchos tipos codificación, como el RGB\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../imagenes/RGB.png\" width=\"200\" height=\"400\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "Aquí no se tiene un número por pixel, sino 3. Teniendo esto tres matrices con información a procesar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df77db18-f050-4e08-9670-25347fd741e1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "A razón de esto, se busca una forma de poder obtener ciertas características de una manera óptima. De aquí salen las convoluciones\n",
    "\n",
    "¿Qué es una convolución? se puede pensar como una multiplicación especial de matrices. Se tiene  la matriz inicial de datos y una segunda matriz llamada \"kernel\". El kernel va a irse \"moviendo\" a través de la matriz de datos y hace una multiplicación de los datos. Depende del kernel, es posible obtener diferentes caraterísticas. Razón por la que el proceso puede repetirse varias veces con diferentes kernel para generar un \"mapa de características\".  Luego de este proceso se aplica una operación en el kernel para representar la información obtenida, este proceso final se conoce como \"pooling\".\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../imagenes/convolution1.gif\" width=\"400\" height=\"400\"/>\n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c62e59f-fb58-4beb-abbd-7a101e493221",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"../imagenes/Image-convolution.png\" width=\"800\" height=\"400\"/>\n",
    "</center>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5758429-d976-4eb5-969f-17d96a0a7130",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Redes Neuronales con capas convolucionales</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e21b17b-51f9-47f0-9701-37f02246d8b4",
   "metadata": {},
   "source": [
    "Utilizando las convoluciones como pasos en la red neuronal, complicamos un poco más el proceso a favor de obtener mayor información. La estructura básica de una red neuronal convolucional \"básica\" para clasificación es parecida a lo siguiente\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"../imagenes/CNN_structure.png\" width=\"400\" height=\"400\"/>\n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e472b5fb-5a03-4072-9dc7-846ee0aa94c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Ejemplo práctico: Clasificación con redes convolucionales</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c315d2f9-c5d2-4946-9b04-0ca0b6e92ffc",
   "metadata": {
    "tags": []
   },
   "source": [
    "[Ejemplo de red neuronal con convoluciones(html)](../Presentaciones/CNN_01_FashionMNIST.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6787dc-27bd-4fa5-87a5-4083d6db5613",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "[Ejemplo de red neuronal con convoluciones(cuaderno)](../Cuadernos/CNN_01_FashionMNIST.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
